{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 11 20:24:22 2017\n",
    "\n",
    "@author: zhonghao\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "def createDataSet():\n",
    "    group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])\n",
    "    labels = ['A','A','B','B']\n",
    "    return group, labels\n",
    "\n",
    "\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]    ## ARRAY.shape = (row, column) ARRAY.shape[0] = row\n",
    "    diffMat = tile(inX, (dataSetSize,1)) - dataSet  ## tile(target, (row, col)) --> duplicate target in row #row times\n",
    "    sqDiffMat = diffMat**2   ## such ele(i) --> f(ele(i)) ONLY FOR array\n",
    "    sqDistances = sqDiffMat.sum(axis=1)  ## ONLY for array, axis= 0 <=> summing up all ROWs\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndicies = distances.argsort()    ## small->big feedback index from 0 to (n-1) \n",
    "    ## Above part sequence 'distance between target&dataSet' and gives coresponding index\n",
    "    \n",
    "    classCount={}          \n",
    "    for i in range(k):  # (0,1,2,... k-1)\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]   # get labels of 1st nearest, 2nd nearest, ... \n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1   ##  statistic jobs using dic, count *each label \\\n",
    "        ## appearance in the first K nearests. \n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True) ## see below line\n",
    "    ## reverse --> we need the most Frequent One, thus Reversed.\n",
    "    ## key --> set the pivot by which we sorting, in our case, it's the frequence\n",
    "        ## operator.itemgetter(1) --> assign (key[0-position], value[1-position])  1-position as pivotal\n",
    "    \n",
    "    return sortedClassCount[0][0]   ## the most frequent one {key, value} <=> sortedClassCount[0]\n",
    "                                    ## we only need its key(the label), thus the second [0] (we don't care about frequence)\n",
    "\n",
    "    \n",
    "def file2matrix(filename):\n",
    "                      \n",
    "    with open(filename, 'r') as fr:     #### with open('txt','r') as txtor: is better\n",
    "        numberOfLines = len(fr.readlines())         #get the number of lines in the file\n",
    "        returnMat = zeros((numberOfLines,3))        #prepare matrix to return\n",
    "        index = 0\n",
    "        classLabelVector = []     #prepare labels return   \n",
    "        for line in fr.readlines():\n",
    "            line = line.strip()   # split the line and get valid elements forming an array\n",
    "            listFromLine = line.split('\\t') # split by \"tab\" and form a list\n",
    "            returnMat[index,:] = listFromLine[0:3]  ## get the [0,1,2] as features\n",
    "            index += 1\n",
    "            classLabelVector.append(int(listFromLine[-1]))  # label is located at the END of rows\n",
    "        \n",
    "    return returnMat,classLabelVector\n",
    "\n",
    "\n",
    "def autoNorm(dataSet):\n",
    "    minVals = dataSet.min(0)    ## min of each column <=> 0 mode\n",
    "    maxVals = dataSet.max(0)    \n",
    "    ranges = maxVals - minVals\n",
    "    normDataSet = zeros(shape(dataSet))   ## shape(dataSet) == dataSet.shape\n",
    "    m = dataSet.shape[0]\n",
    "    normDataSet = dataSet - tile(minVals, (m,1))  ## delete bias\n",
    "    normDataSet = normDataSet/tile(ranges, (m,1))   ## normalization\n",
    "    return normDataSet, ranges, minVals\n",
    "\n",
    "## Below Un-learnt\n",
    "def datingClassTest():\n",
    "    hoRatio = 0.50      #hold out 10%\n",
    "    datingDataMat,datingLabels = file2matrix('datingTestSet2.txt')       #load data setfrom file\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    m = normMat.shape[0]\n",
    "    numTestVecs = int(m*hoRatio)\n",
    "    errorCount = 0.0\n",
    "    for i in range(numTestVecs):\n",
    "        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)\n",
    "        print \"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, datingLabels[i])\n",
    "        if (classifierResult != datingLabels[i]): errorCount += 1.0\n",
    "    print \"the total error rate is: %f\" % (errorCount/float(numTestVecs))\n",
    "    print errorCount\n",
    "\n",
    "    \n",
    "def classifyPerson():\n",
    "    resultList = ['no!!', 'little', 'rave']\n",
    "    percentTats = float(raw_input('time of Games=?'))\n",
    "    ffMile = float(raw_input('freq Flye Miles / yeear=?'))\n",
    "    iceCream = float(raw_input('ice Cream consumed / year=?'))\n",
    "    datingDatMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    normMat, ranges, minVals = autoNorm(datingDatMat)\n",
    "    inArr = array([ffMile, percentTats, iceCream])\n",
    "    classifierResult = classify0((inArr - minVals)/ranges, normMat, datingLabels, 3)\n",
    "    print(resultList[classifierResult -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet =  array([[1.0,10, 100],[1.0,12, 110],[0,9, 120],[0,15, 140]])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.min(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  0.16666667,  0.        ],\n",
       "        [ 1.        ,  0.5       ,  0.25      ],\n",
       "        [ 0.        ,  0.        ,  0.5       ],\n",
       "        [ 0.        ,  1.        ,  1.        ]]),\n",
       " array([  1.,   6.,  40.]),\n",
       " array([   0.,    9.,  100.]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoNorm(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4L, 3L)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4L, 3L)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
